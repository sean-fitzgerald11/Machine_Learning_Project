<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>Sean Fitzgerald | Machine Learning</title>
  <style>
    body {
      margin: 0;
      font-family: Arial, sans-serif;
      background-color: #f5f5f5;
    }

    .top-bar {
      display: flex;
      justify-content: space-between;
      align-items: flex-start;
      background-color: #24292e;
      color: white;
      padding: 20px;
      flex-wrap: wrap;
    }

    .personal-info {
      line-height: 1.4;
    }

    .personal-info div:first-child {
      font-size: 1.5em;
      font-weight: bold;
    }

    .nav-menu {
      display: flex;
      gap: 10px;
      flex-wrap: wrap;
      margin-top: 5px;
    }

    .nav-menu a {
      color: white;
      text-decoration: none;
      font-weight: bold;
      padding: 6px 12px;
      border-radius: 4px;
      transition: background 0.3s;
    }

    .nav-menu a:hover {
      background-color: #444;
    }

    .content {
      padding: 40px;
    }

    .page {
      display: none;
    }

    .page.active {
      display: block;
    }
  </style>
</head>
<body>
  <div class="top-bar">
    <div class="personal-info">
      <div>Sean Fitzgerald</div>
      <div>Machine Learning (CSCI 5612)</div>
      <div>MSDS; CU Boulder</div>
    </div>
    <div class="nav-menu">
      <a href="#introduction">Introduction</a>
      <a href="#dataprep_eda">DataPrep_EDA</a>
      <a href="#pca">PCA</a>
      <a href="#clustering">Clustering</a>
      <a href="#naivebayes">NaiveBayes</a>
      <a href="#dectrees">DecTrees</a>
      <a href="#svms">SVMs</a>
      <a href="#regression">Regression</a>
      <a href="#nn">NN</a>
      <a href="#conclusions">Conclusions</a>
      <a href="#about_me">About Me</a>
    </div>
  </div>

  <div class="content">
    <div id="introduction" class="page active">
      <h1>Introduction</h1>
      <p>Global warming and climate change have been topics of national and international discussion for decades. Countless research and 
        academic papers how quantified and solidified the effects that human activity is having on our climate, specifically the average temperature 
        of our planet. However, despite the urgency, it seems less and less likely that the necessary steps to avoid the worst outcomes are 
        likely to be taken in the time necessary. Thus, it is important to continue to work to understand as much as we can about our climate 
        and how it is changing. However, it is also becoming increasinly important to understand the implications that a changing climate will 
        have on our lived environment. This understanding includes the changes to severe weather events such as wilfires, droughts, hurricanes, 
        tornados. It also includes changes to experienced droughts or heavy rain events, the intensity of temperatures during different seasons, 
        especially summer and winter. All of these changes will most likely be materailly felt by all. Therefore, understanding the impacts that 
        can be expected can assists people in adapting to this changing climate and changing world.  
      </p>
      <p>In an effort to provide accurate and useful data in which to conduct historical climate analyses, NOAA generates and provides the Climate 
        Divisional Dataset. For many years this was the only available long-term temporally and spatially complete dataset (NCEI,NOAA,https://www.ncei.noaa.gov/access/monitoring/dyk/us-climate-divisions). 
        The breakdown of climate division for the contiguous United States can be seen below in Figure 1.
      </p>
      <img src="Images/us-climate-divisions.gif" style="display: block; margin: 0 auto;" alt="Figure 1. United States Climate Divisions">
      <p>The climate divisions above were determined based on identifying regions with similar climate conditions based on geographical features, vegeation, and 
        weather patterns. Below, in Figure 2, we can see a close up of the climate divisions within Colorado. We can observe that for Colorado, the most impactful 
        boundary between the divisions are the topological features of the state. Most of the division boundaries consist of mountainous or elevated terrain.
      </p>
      <img src="Images/Colorado Climate Divisions.png" style="display: block; margin: 0 auto;" alt="Figure 2. Colorado Climate Divisions">
      <p>It stands to reason that due to these differences in climate division, people living within Colorado stand to experience the effects of climate change differently
        depending on where they are located within the state. These differences might include changes in average maximum or minimum temperature or experience of drought or 
        rain events. Additionally, the the impacts of a changing climate could be felt in a change of the air quality that someone experiences. The Intergovernmental Panel 
        on Climate Change and the United States Environmental Protection Agency have both recognized the potential for climate change to impact the air quality that we 
        experience. 
      </p>
      <p>Ten questions that I would like to answer thorugh my research are:
      <ol>
        <li>Is there a significant difference in the trend of maximum and minimum temperature change over time between the different climate divsions?</li>
        <li>Is there a significant difference in the amount of precipitation experienced over time by each climate division?</li>
        <li>Is there a significant difference in the occurence and severity of drought experienced by each climate division?</li>
        <li>Is there a significant difference in the number of Heating Degree Days or Cooling Degree Days experienced by each climate division?</li>
        <li>Based on the differences in trends experienced, which climate division will has been most affected by climate change? Which one has been least affected?</li>
        <li>Is there a difference in air quality changes over time depending on the climate division being observed?</li>
        <li>Which climate division has experienced the greatest impact to their air quality? Is this most likely due to climate change or other factors?</li>
        <li>Which climate division has experienced the least impact to their air quality? Why might this be?</li>
        <li>Based on both climate trends and air quality trends, which climate division appears to be the most desirable to live in if climate trends continue?</li>
        <li>What additional research and investigation should be conducted in order to further this anlysis?</li>
      </ol>
      </p>
    </div>

    <div id="dataprep_eda" class="page">
      <h1>Data Preparation & EDA</h1>
      <h2>Climate Data</h2>
      <p>The climate data collected for this analysis was from the <a href="https://www.ncei.noaa.gov/access/metadata/landing-page/bin/iso?id=gov.noaa.ncdc:C00005" target="_blank">National Oceanic and Atmospheric Administration (NOAA)</a>. 
        NOAA maintains and publishes a thorough, temporal, and spatially aligned dataset called the Global Historical Climatology Network (GHCN) Daily dataset. This dataset is the 
        basis for the Climate Divisions datasets, which are being used in this analysis. These datasets are aggregations of the GHCN-Daily. The independent 
        station data is interpolated to grid-point estimates and then area-weighted to determine the recorded value for the climate division. 17 total datasets 
        were downloaded to cover data including temperature, precipitation, heating and cooling degree days, and a variety of drought indexes. A sample of 
        the raw data can be seen below in Figure 3.
      </p>
      <img src="Images/NOAA_Raw_Data.png" style="display: block; margin: 0 auto;" alt="Figure 3. Raw NOAA Data">
      <p>As can be seen above, this data is provided in wide format with monthly values for each climate division. Additionally, this data table is only for 
        element code 07, which is the code for the Palmer "Z" Index. Additional data tables for the 16 other variables were also produced in a similar manner. In 
        order to allow for all 17 variable tables to be merged into a singular dataset, each table was converted to a long format with a new column for the values 
        for that variable. The tables were then merged, a new date column was constructed to combine the year and month, and the element code column was removed. The 
        last step was to remove any values that were stand ins for missing or inaccurate data. The documenation noted that missing values for variables would be denoted 
        with -9.99, -99.90, -99.99, or -9999, depending on the variable. These values were dropped and replaced with NaNs. The reasoning for replacing with NaN instead 
        of imputing values was due to the fact that the missing value was mostly likely due to unreported or incorrectly reported data. As discussed earlier, the data 
        in these datasets were interpolated and area-weighted data already. Therefore, it was decided that any attempt at imputing a value for the missing value would 
        just be a re-interpolation or aggregation of data that was already interpolated/aggregated. Without knowing the exact data points that were used to 
        formulate climate division data, any additional interpolation or aggregation could have potentially given undue weight to certain original indepent station 
        observations, skewing the data for the entire division towards that one area. A sample of the final cleaned dataset for the NOAA data can be seen below in Figure 4. The 
        code for the processing and cleaning of the data can be found in the GitHub repository for this project <a href="https://github.com/sean-fitzgerald11/Machine_Learning_Project/tree/main/Code" 
        target="_blank">here</a>. The name of the code file is 'NOAA Data Import and Cleaning.ipynb'.
      </p>
      <img src="Images/NOAA_Data_Cleaned.png" style="display: block; margin: 0 auto;" alt="Figure 4. Cleaned NOAA Data">
      <h2>AirNow Data</h2>
      <p>The second part of the dataset for this analysis was collected from <a href="https://www.airnow.gov/" target="_blank">AirNow.gov</a>. AirNow is a partnership of the United States Environmental Protection Agency (EPA), 
        NOAA, National Park Service (NPS), NASA, Centers for Disease Control (CDC), and local, state, and tribal air quality agencies. AirNow centralized data system 
        provides quality control, national reporting consistency, and the ability to distrbute data to the public. The AirNow data for this analysis was collected by two different 
        means. The first was through the use of AirNow's Application Programming Interface (API). This API allowed for the download of historical hourly air quality data from 54 
        different sensor stations across Colorado. Through the use of this API data was downloaded for January 1st, 2024 through July 31st, 2025. The reason for this small time period
        was due to the massive amount of data included in each day and the rate limit imposed by the API. The API endpoint for this specific data was 'Observations by Monitoring Site'. 
        The documentation for this endpoint can be found on AirNow's website <a href="https://docs.airnowapi.org/Data/docs" target="_blank">here</a>. The implementation of the API call 
        can be seen below in Figure 5. The GET url was dynamically changed during the code execution which allowed for multiple GET calls to be executed while the code was running. 
        The full code for the API implementation can be found <a href="https://github.com/sean-fitzgerald11/Machine_Learning_Project/tree/main/Code" target="_blank">here</a>. The file name 
        for the code is 'AirNow API for Data Acquisition'.
      </p>
      <img src="Images/API_Code.png" style="display: block; margin: 0 auto;" alt="Figure 5. API Code">
      <img src="Images/AirNow_Raw_Data.png" style="display: block; margin: 0 auto;" alt="Figure 6. Raw AirNow Data">
      <p>The raw AirNow data can be seen above in Figure 6. The data in this raw form was in long format, with all of the different parameters listed in one column and each 
        station having multiple entries depending on which parameter was being recorded. The first thing that was done was to map each staion ID to the 
        climate division that it was located in. This would faciliate aggregating the data up to the climate division level. Next, in order to simplify the data structure, 
        the table was converted to a wide format so that each parameter had its own column. At the same time, values for each parameter were agregated up to the division level. This 
        yielded the final cleaned data structure that can be seen below in Figure 7. This data now had one entry for each climate division for each day of record with the aggregate 
        values for each parameter. The code for this data cleaning can be found <a href="https://github.com/sean-fitzgerald11/Machine_Learning_Project/tree/main/Code" target="_blank">here</a>.
      </p>
      <img src="Images/AirNow_Data_Cleaned.png" style="display: block; margin: 0 auto;" alt="Figure 7. Clean AirNow Data">
      <h2>Data Exploration and Visualization</h2>
      <p>Once all of the data was cleaned, it was time to explore the data. This exploration allowed for a better understanding of the data and what 
        potential trends or relationships might be learned from the data. This exploration also highlighted which variables were severely lacking in avaiable data. Those variables 
        will be noted and possibly excluded during future analysis due to their lack of temporal availability in relation to the rest of the data.
      </p>
      <img src="Images/Max Temp Over Time by Division.png" style="display: block; margin: 0 auto;" alt="Figure 8. Viz group 1">
      <p>The above grid shows a comparison of the maximum temperature for the year from 1895 to 2025 for each climate division.
        It is interesting to note that each division has a different temperature profile that it oscilates between. However, it appears 
        from visual inspection that each division does have an upward trend in temperature, as would be expected.
      </p>
      <img src="Images/Avg Temp Over Time by Division.png" style="display: block; margin: 0 auto;" alt="Figure 9. Viz group 2">
      <p>The above grid shows a comparison of the average temperature for the year from 1895 to 2025 for each climate division. Similar to 
        the maximum temperature, we can see a clear separation in the temperature variation range depending on climate division.
      </p>
      <img src="Images/PDSI Over Time_Division 4.png" style="display: block; margin: 0 auto;" alt="Figure 10. Viz 5">
      <p>This graph shows the PDSI value over time. A positive PDSI value means means a wet spell while a negative value indicates a dry spell. 
        The PDSI is used to gauge the severity of dry or wet spell. Over time, it appears as though climate division 4 is spending more time with a 
        PDSI that is negative, indicating an more drought stricken environment.
      </p>
      <img src="Images/Total HDD_Division 3.png" style="display: block; margin: 0 auto;" alt="Figure 11. Viz 6">
      <p>This graph shows the total value of Heating Degree Days by year, over time. A higher value for a year would indicate colder temperatures on average 
        over the year, implying more heating would be needed to maintain comfortable temperatures inside. The plot suggests a downward trend, meaning less 
        need for heating over the year.
      </p>
      <img src="Images/Total CDD_Division 3.png" style="display: block; margin: 0 auto;" alt="Figure 12. Viz 7">
      <p>This graph show the total value of Cooling Degree Days by year, over time. A higher value for a year would indicate hotter temperatures on average 
        over the year, implying more cooling would be needed to maintain comfortable temperatures inside. The plot suggests a upward trend, meaning more 
        need for cooling over the year.
      </p>
      <img src="Images/PM10_Division 4.png" style="display: block; margin: 0 auto;" alt="Figure 13. Viz 8">
      <p>This graph shows the Coarse Particulate Matter concentrations (PM10, micrograms per cubic meter) daily readings over time for climate division 4. From initial 
        inspection it does not appear as though any general trend is present within the data. More exploration will be needed to see if any conclusions can be 
      drawn from this data and connected to any climate conclusions.
    </p>
      <img src="Images/NO2_Division 4.png" style="display: block; margin: 0 auto;" alt="Figure 14. Viz 9">
      <p>This graph show the Nitrogen Dioxide concentrations for climate division 4 over time. The graph suggests that the concentrations are both decreased over the 
        entire time period and also have shown less variability. A slight upward trend could potentially be materializing, as observed in the last part of the line graph.
      </p>
      <img src="Images/SO2_Division 4.png" style="display: block; margin: 0 auto;" alt="Figure 15. Viz 10">
      <p>This graph shows the Sulphur Dioxide concentrations for climate division 4 over time. The graph shows that a lot of historical data is missing for these measurements, 
        as indicated by the stretches of line that lie on the zero line for the y-axis. However, concentration measurements seem to have increased in quality in recent times and 
        appear to be showing a strong general upward trend.
      </p>
    </div>

    <div id="pca" class="page">
      <h1>Principal Component Analysis (PCA)</h1>
      <p>Explaining dimensionality reduction using PCA.</p>
    </div>

    <div id="clustering" class="page">
      <h1>Clustering</h1>
      <h2>Overview</h2>
      <p>Clustering is an unspervised machine learning technique that uses unlabeled data to discover groupings or patterns within a dataset. 
        Unspervised means that the model does not have any target outputs that it is trained on like a regression model. It is not trying to predict 
        a specific outcome or achieve a particular accuracy. Instead, the model is left to discover patterns on its own. The two clustering models that 
        where utilized were K-Means clustering and Hierarchical Clustering.
      </p> 
      <p>K-Means clustering works by first setting locations for the centroids for each cluster. The k value specified determines the number of resulting 
        clusters and therefore the number of centroids that are initially set. Then, the algorithm measures the distance from one point to each of the centroids. 
        The distance measurement used for the K-Means clustering in this project was the Euclidean distance. The point is then assigned to cluster of the centroid that is the closetst. 
        This happens for each point in the dataset. Once all points have been assigned, the centroids are recalculated so that they are moved to the center 
        of the points that were assigned to their cluster. Then, the process happens again. The distance from a point to all the centroids is calculated. If a 
        point is now closer to a different centroid it is reassigned to that cluster. All the points are rechecked and reassigned if necessary. Then the centroids 
        are recalculated and adjusted. This process continues until no points are reassigned and the centroids do not need to be adjusted.
      </p>
      <p>Hierarchical clustering works in a different manner. It takes all points in a dataset and assigns each point to its own cluster. It then calculates the 
        distance between each pair of clusters and merges each cluster pair that has the smallest distance between them. It then recalculates the distance between all 
        the new cluster pairs and again merges each cluster pair that has the smallest distance between them. This merging continues until you end up with one final cluster. This 
        process allows us to see how our data is iteratively clustered so that we can pick an appropriate number of clusters for our data that will provide an appropriate amount of 
        segmentation for analysis and interpretability.
      </p>
      <p>These techniques will be used to discover multivariate interactions within our dataset, which includes climate and air quality data for the state of Colorado. In Figure 1 below, 
        the visualization of K-Means clustering gives an example of the clustering that will occur. This figure is a 2-D representation, however the dataset to be clustered will 
        contain 10 different variables, so it will not be possible to visualize the data in this hyperdimensional space. Figure 2 below is an example of a Dendrogram. This visualization 
        shows the agglomerative clustering process of the hierarchical clustering technique in visual form. On the x-axis is each individual point. The lines then show how the points and 
        clusters were merged together to get larger and larger clusters. 
      </p>
      <figure style="text-align: center;">
      <img src="Images/K-Means.png" style="display: block; margin: 0 auto;" alt="Figure 1. K-Means">
      <figcaption style="font-size: 0.9em; color:gray;">Source: Geeks for Geeks (https://www.geeksforgeeks.org/machine-learning/ml-k-means-algorithm/)</figcaption>
      </figure>
      <figure style="text-align: center;">
      <img src="Images/Dendrogram-Example.png" style="display: block; margin: 0 auto;" alt="Figure 1. Dendrogram Example">
      <figcaption style="font-size: 0.9em; color:gray;">Source: Data Novia (https://www.datanovia.com/en/lessons/examples-of-dendrograms-visualization/)</figcaption>
      </figure>
      <h2>Data Prep</h2>
      <p></p>
      <h2>Results</h2>
      <p></p>
      <h2>Conclusions</h2>
      <p></p>
    </div>

    <div id="naivebayes" class="page">
      <h1>Naive Bayes</h1>
      <p>Using probabilistic classifiers for text and numeric data.</p>
    </div>

    <div id="dectrees" class="page">
      <h1>Decision Trees</h1>
      <p>Entropy, Information Gain, and building decision trees.</p>
    </div>

    <div id="svms" class="page">
      <h1>Support Vector Machines (SVMs)</h1>
      <p>Kernel methods, margin maximization, and classification.</p>
    </div>

    <div id="regression" class="page">
      <h1>Regression</h1>
      <p>Linear and logistic regression analysis.</p>
    </div>

    <div id="nn" class="page">
      <h1>Neural Networks (NN)</h1>
      <p>Architecture, backpropagation, and training deep models.</p>
    </div>

    <div id="conclusions" class="page">
      <h1>Conclusions</h1>
      <p>Summary of findings and reflections on the course and project.</p>
    </div>

    <div id="about_me" class="page">
      <h1>About the Author</h1>
      <img src="Images/Sean Bio Pic.jpg" style="display: block; margin: 0 auto;" alt="Figure #. Bio Picture">
      <p>Sean Fitzgerald
         Sean was commissioned as an officer in the United States Army in May 2013. Since then, he has held numerous 
         leadership and staff positions from the tactical to organizational level. Sean spent 4 years as an Infantry 
         Officer and 7 years as a Military Intelligence Officer. In 2024, Sean reclassified as an Operations Research 
         and Systems Analysis Officer. As part of this transition, Sean has enrolled in the Master's of Data Science 
         program at University of Colorado, Boulder with an anticipated graduation date of May 2026.
      </p>
    </div>
  </div>

  <script>
    function showPageFromHash() {
      const hash = window.location.hash.substring(1) || 'introduction';
      document.querySelectorAll('.page').forEach(page => {
        page.classList.remove('active');
      });
      const activePage = document.getElementById(hash);
      if (activePage) {
        activePage.classList.add('active');
      }
    }

    window.addEventListener('hashchange', showPageFromHash);
    window.addEventListener('DOMContentLoaded', showPageFromHash);
  </script>
</body>
</html>
